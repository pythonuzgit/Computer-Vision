{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6j67X+b89d0KJxynwvKrA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pythonuzgit/elmurodov/blob/master/Graph%20Neural%20Network/Graph_Neural_Network_in_NLP_with_Movies_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s89VrT_KdxPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSQHfjGndxAi",
        "outputId": "e25cf115-ceb6-4506-881d-08b3ecc0f6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=4a1173eff1c699fe25bc55024335f165c52eb9b810c6f846411825c364a455dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import"
      ],
      "metadata": {
        "id": "fXOy3puO5nXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "8F5wJ463d5kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the code search dataset"
      ],
      "metadata": {
        "id": "2vNnvwSn4kWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Movies_dataset.csv')"
      ],
      "metadata": {
        "id": "NCgZ_0rPd5gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJOc2Jzcd5W7",
        "outputId": "19ea8e4e-ae37-4568-c48c-e2e80c8240a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w24k04rMd5TI",
        "outputId": "c06442a4-c3fe-4b6c-cf98-4626d64a9f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['index', 'title', 'original_language', 'release_date', 'popularity',\n",
              "       'vote_average', 'vote_count', 'overview'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select the relevant columns"
      ],
      "metadata": {
        "id": "OVS7iDHD4sQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = ['index', 'title', 'overview']\n",
        "df = df[selected_columns]"
      ],
      "metadata": {
        "id": "wn8WACkrZpWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(data):\n",
        "    # Drop any rows with missing values\n",
        "    #data.dropna(inplace=True)\n",
        "\n",
        "    # Tokenize 'text' and 'code' columns\n",
        "    vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
        "    text_features = vectorizer.fit_transform(data['title'])\n",
        "    code_features = vectorizer.fit_transform(data['overview'])\n",
        "\n",
        "    # Normalize features\n",
        "    scaler = StandardScaler()\n",
        "    text_features = scaler.fit_transform(text_features.toarray())\n",
        "    code_features = scaler.fit_transform(code_features.toarray())\n",
        "\n",
        "    # Split into features and labels\n",
        "    X = np.concatenate((text_features, code_features), axis=1)\n",
        "    y = data['index']\n",
        "\n",
        "     #Split into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create the processed DataFrame\n",
        "    column_names = list(data.columns)[:-1]  # Exclude the 'task_id' column\n",
        "    processed_data = pd.DataFrame({col: X_train[:, i] for i, col in enumerate(column_names)})\n",
        "    processed_data['index'] = y_train\n",
        "\n",
        "    return processed_data, X_test, y_test"
      ],
      "metadata": {
        "id": "q5m2KbxjZ924"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data, X_test, y_test = preprocess_data(df)"
      ],
      "metadata": {
        "id": "J5ewn8uWZ9za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create graph representation"
      ],
      "metadata": {
        "id": "rNqHmKrA44xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_graph_representation(data):\n",
        "    edge_index = np.array([[i, i] for i in range(len(data))]).T\n",
        "    x = torch.tensor(data.drop(['index'], axis=1).values, dtype=torch.float)\n",
        "    y = torch.tensor(data['index'].values, dtype=torch.long)\n",
        "    return Data(x=x, edge_index=edge_index, y=y)"
      ],
      "metadata": {
        "id": "sOa42HWRZ9wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_data = create_graph_representation(processed_data)"
      ],
      "metadata": {
        "id": "lj5NIwWtZ9tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the GNN model"
      ],
      "metadata": {
        "id": "IwN62IOk48Tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "EsOlukmwZ9q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the device for computation"
      ],
      "metadata": {
        "id": "5xrr2btE5BlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "fNlAuqmqZ9nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the GNN model"
      ],
      "metadata": {
        "id": "J7bEdt9e5JyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_dim = graph_data.num_node_features\n",
        "hidden_dim = 64\n",
        "output_dim = len(processed_data['index'].unique())\n",
        "model = GNNModel(input_dim, hidden_dim, output_dim).to(device)"
      ],
      "metadata": {
        "id": "BtOQHUDiZ9kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the loss function and optimizer"
      ],
      "metadata": {
        "id": "36byUA5m5Nux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "OblVZdilZ9gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the custom collate function"
      ],
      "metadata": {
        "id": "D_L5mP2y5PjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    return batch\n",
        "\n",
        "# Create the DataLoader\n",
        "data_loader = DataLoader([graph_data], batch_size=1, shuffle=True, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "2BgSVyPQa-1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the custom collate function"
      ],
      "metadata": {
        "id": "LPYHWJ0p5YBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def collate_fn(batch):\n",
        "    x = [data.x for data in batch]\n",
        "    edge_index = [data.edge_index for data in batch]\n",
        "    y = [data.y for data in batch]\n",
        "    return {'x': x, 'edge_index': edge_index, 'y': y}\n",
        "\n",
        "# Convert the graph data to PyTorch DataLoader\n",
        "data_loader = DataLoader([graph_data], batch_size=1, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "cRiPJapza-yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in data_loader:\n",
        "    x = torch.tensor(data['x'][0], dtype=torch.float).to(device)\n",
        "    edge_index = torch.tensor(data['edge_index'][0], dtype=torch.long).to(device)\n",
        "    y = torch.tensor(data['y'][0], dtype=torch.float).to(device)\n",
        "\n",
        "    # Normalize the target values\n",
        "    y_min = torch.min(y)\n",
        "    y_max = torch.max(y)\n",
        "    y_normalized = (y - y_min) / (y_max - y_min)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    out = model(x, edge_index)\n",
        "\n",
        "    # Verify the target values range\n",
        "    print(f\"Min target value: {torch.min(y_normalized).item()}\")\n",
        "    print(f\"Max target value: {torch.max(y_normalized).item()}\")\n",
        "\n",
        "    # Convert y_normalized to torch.long\n",
        "    y_normalized = y_normalized.long()\n",
        "\n",
        "    loss = criterion(out, y_normalized)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlcimJjka-vw",
        "outputId": "1ec5406a-4628-417d-e415-b52d83800ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-3cff8116b1d4>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(data['x'][0], dtype=torch.float).to(device)\n",
            "<ipython-input-26-3cff8116b1d4>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y = torch.tensor(data['y'][0], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min target value: 0.0\n",
            "Max target value: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the model"
      ],
      "metadata": {
        "id": "7z6DC8GB5eoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.eval()\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in data_loader:\n",
        "        x = torch.tensor(data['x'][0], dtype=torch.float).to(device)\n",
        "        edge_index = torch.tensor(data['edge_index'][0], dtype=torch.long).to(device)\n",
        "        y = torch.tensor(data['y'][0], dtype=torch.float).to(device)\n",
        "\n",
        "        # Normalize the target values\n",
        "        y_min = torch.min(y)\n",
        "        y_max = torch.max(y)\n",
        "        y_normalized = (y - y_min) / (y_max - y_min)\n",
        "\n",
        "        out = model(x, edge_index)\n",
        "        _, predicted = torch.max(out, dim=1)\n",
        "        total_correct += (predicted == y_normalized).sum().item()\n",
        "        total_samples += y_normalized.size(0)\n",
        "\n",
        "accuracy = total_correct / total_samples\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGUhtl3ga-st",
        "outputId": "98dd6b5a-d6c0-4a53-9cd5-014bb6ffecdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-906453e50160>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(data['x'][0], dtype=torch.float).to(device)\n",
            "<ipython-input-27-906453e50160>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y = torch.tensor(data['y'][0], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 79.84%\n"
          ]
        }
      ]
    }
  ]
}