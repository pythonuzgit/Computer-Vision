{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image classification using CNN in PyTorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNmXmNopAYwCOUSfBvaLkYf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pythonuzgit/elmurodov/blob/master/Convolutional%20neural%20network/Image_classification_using_CNN_in_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFObbHMrULWL",
        "outputId": "49c8544b-a751-41f3-9bda-3769849edb22"
      },
      "source": [
        "!kaggle datasets download -d dibakarsil/9-classes-noisy-image-dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 9-classes-noisy-image-dataset.zip to /content\n",
            "100% 5.34G/5.35G [01:54<00:00, 29.4MB/s]\n",
            "100% 5.35G/5.35G [01:54<00:00, 50.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjQuEQd4ULZZ",
        "outputId": "1a4f4c52-dac2-4084-a286-ca5b44008692"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/9-classes-noisy-image-dataset.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odFad8nGULc5"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import pathlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQfBrFLSKO1p"
      },
      "source": [
        "Checking for device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv_jVhR5J3pG"
      },
      "source": [
        "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtnLaktEKhwQ",
        "outputId": "f47b1be6-1545-4f3e-f359-65af733c3067"
      },
      "source": [
        "print(dev)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbt4Yg2RKNv2"
      },
      "source": [
        "Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBskb1ifKo_s"
      },
      "source": [
        "transformer = transforms.Compose([\n",
        "                                  transforms.Resize((150, 150)),\n",
        "                                  transforms.RandomHorizontalFlip(),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize([0.5, 0.5, 0.5],\n",
        "                                                       [0.5, 0.5, 0.5])\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S6Qh7RaLrzY"
      },
      "source": [
        "Load training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBfcABzRLPSQ"
      },
      "source": [
        "train_path = '/content/dataset/train_im'\n",
        "test_path = '/content/dataset/test_im'\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    torchvision.datasets.ImageFolder(\n",
        "        train_path, transform = transformer), batch_size = 256, shuffle = True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    torchvision.datasets.ImageFolder(\n",
        "        test_path, transform = transformer), batch_size = 256, shuffle = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ensMyr3MNssm"
      },
      "source": [
        "Categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gryPDGRNrvI",
        "outputId": "34a7211d-7096-443c-801b-a6a8e927625a"
      },
      "source": [
        "root = pathlib.Path(train_path)\n",
        "classes = sorted([j.name.split('/')[-1]\n",
        "                  for j in root.iterdir()])\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['erlang', 'exponential', 'gaussian', 'lognormal', 'poisson', 'rayleigh', 'saltpepper', 'speckle', 'uniform']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wawE4qMSUjlM",
        "outputId": "98f47d48-f8d9-4cbe-b3bf-dcac0e4911bc"
      },
      "source": [
        "len(classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OnLA2H-OOKm"
      },
      "source": [
        "Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiiZv__VcrXA"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self, num_classes = 6):\n",
        "    super(ConvNet, self).__init__()\n",
        "\n",
        "    #Output size after convolutional filter\n",
        "    #((w - f + 2*P)/ s) + 1\n",
        "\n",
        "    #input shape = (256, 3, 150, 150)\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 12, kernel_size = 3,\n",
        "                           stride = 1, padding = 1)\n",
        "    \n",
        "    #Shape = (256, 12, 150, 150)\n",
        "\n",
        "    self.bn1 = nn.BatchNorm2d(num_features = 12)\n",
        "\n",
        "    #Shape = (256, 12, 150, 150)\n",
        "\n",
        "    self.relu1 = nn.ReLU()\n",
        "\n",
        "    #Shape = (256, 12, 150, 150)\n",
        "\n",
        "    self.pool = nn.MaxPool2d(kernel_size = 2)\n",
        "\n",
        "    #Reduce the image size be factor 2\n",
        "    #Shape = (256, 12, 75, 75)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels = 12, out_channels = 20, kernel_size = 3,\n",
        "                           stride = 1, padding = 1)\n",
        "    \n",
        "    #Shape = (256, 20, 150, 150)\n",
        "\n",
        "    self.relu2 = nn.ReLU()\n",
        "\n",
        "    #Shape = (256, 20, 75, 75)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels = 20, out_channels = 32,\n",
        "                           kernel_size = 3, stride = 1, padding = 1)\n",
        "\n",
        "    #Shape = (256, 32, 75, 75)\n",
        "\n",
        "    self.bn3 = nn.BatchNorm2d(num_features = 32)\n",
        "\n",
        "    #Shape = (256, 32, 75, 75)\n",
        "\n",
        "    self.relu3 = nn.ReLU()\n",
        "\n",
        "    #Shape = (256, 32, 75, 75)\n",
        "\n",
        "    self.fc = nn.Linear(in_features = 32*75*75, out_features = num_classes)\n",
        "\n",
        "  def forward(self, input):\n",
        "    output = self.conv1(input)\n",
        "    output = self.bn1(output)\n",
        "    output = self.relu1(output)\n",
        "\n",
        "    output = self.pool(output)\n",
        "\n",
        "    output = self.conv2(output)\n",
        "    output = self.relu2(output)\n",
        "\n",
        "    output = self.conv3(output)\n",
        "    output = self.bn3(output)\n",
        "    output = self.relu3(output)\n",
        "\n",
        "    output = output.view(-1, 32 * 75 * 75)\n",
        "\n",
        "    output = self.fc(output)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7YhDYXKR4ow"
      },
      "source": [
        "Defining training parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cUydh6ORm_T"
      },
      "source": [
        "model = ConvNet(num_classes = 9)\n",
        "model = model.cuda()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu3KHqhiSMeE"
      },
      "source": [
        "Loss and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDaPdcJxSD7k"
      },
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swc-s4y1Srtg"
      },
      "source": [
        "num_epochs = 25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybqNxK_SVfz-"
      },
      "source": [
        "Calculating training and testing datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKJdwjmZVelo"
      },
      "source": [
        "train_count = len(glob.glob(train_path + '/**/*.jpg'))\n",
        "test_count = len(glob.glob(test_path + '/**/*.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSxqXFnmVxf9",
        "outputId": "4435074f-27c8-4464-d0c8-1bfed3f4f768"
      },
      "source": [
        "print(train_count, test_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12000 2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqbqVZZUVxeT",
        "outputId": "0e29f929-2eb8-45e0-c976-3680d6e951ef"
      },
      "source": [
        "best_accuracy = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  train_accuracy = 0.0\n",
        "  train_loss = 0.0\n",
        "\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    if torch.cuda.is_available:\n",
        "      images = Variable(images.cuda())\n",
        "      labels = Variable(labels.cuda())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = loss_function(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.cpu().data * images.size(0)\n",
        "    _, prediction = torch.max(outputs.data, 1)\n",
        "    train_accuracy += int(torch.sum(prediction == labels.data))\n",
        "\n",
        "  train_accuracy = train_accuracy/train_count\n",
        "  train_loss = train_loss/train_count\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  test_accuracy = 0.0\n",
        "\n",
        "  for i, (images, labels) in enumerate(test_loader):\n",
        "    if torch.cuda.is_available:\n",
        "      images = Variable(images.cuda())\n",
        "      labels = Variable(labels.cuda())\n",
        "\n",
        "    outputs = model(images)\n",
        "    _, prediction = torch.max(outputs.data, 1)\n",
        "    test_accuracy += int(torch.sum(prediction == labels.data))\n",
        "\n",
        " \n",
        "  test_accuracy = test_accuracy/test_count\n",
        "\n",
        "\n",
        "\n",
        "  print('Epoch: '+str(epoch)+' Train loss: '+str(int(train_loss))+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train loss: 0 Train Accuracy: 0.76025 Test Accuracy: 0.22\n",
            "Epoch: 1 Train loss: 0 Train Accuracy: 0.7798333333333334 Test Accuracy: 0.2955\n",
            "Epoch: 2 Train loss: 0 Train Accuracy: 0.7935 Test Accuracy: 0.2355\n",
            "Epoch: 3 Train loss: 0 Train Accuracy: 0.8101666666666667 Test Accuracy: 0.2945\n",
            "Epoch: 4 Train loss: 0 Train Accuracy: 0.8105833333333333 Test Accuracy: 0.2275\n",
            "Epoch: 5 Train loss: 0 Train Accuracy: 0.8278333333333333 Test Accuracy: 0.2145\n",
            "Epoch: 6 Train loss: 0 Train Accuracy: 0.8225833333333333 Test Accuracy: 0.2895\n",
            "Epoch: 7 Train loss: 0 Train Accuracy: 0.8273333333333334 Test Accuracy: 0.34\n",
            "Epoch: 8 Train loss: 0 Train Accuracy: 0.8055833333333333 Test Accuracy: 0.2885\n",
            "Epoch: 9 Train loss: 0 Train Accuracy: 0.761 Test Accuracy: 0.227\n",
            "Epoch: 10 Train loss: 0 Train Accuracy: 0.80075 Test Accuracy: 0.222\n",
            "Epoch: 11 Train loss: 0 Train Accuracy: 0.8158333333333333 Test Accuracy: 0.242\n",
            "Epoch: 12 Train loss: 0 Train Accuracy: 0.8365833333333333 Test Accuracy: 0.35\n",
            "Epoch: 13 Train loss: 0 Train Accuracy: 0.8491666666666666 Test Accuracy: 0.3005\n",
            "Epoch: 14 Train loss: 0 Train Accuracy: 0.851 Test Accuracy: 0.246\n",
            "Epoch: 15 Train loss: 0 Train Accuracy: 0.8298333333333333 Test Accuracy: 0.254\n",
            "Epoch: 16 Train loss: 0 Train Accuracy: 0.849 Test Accuracy: 0.3245\n",
            "Epoch: 17 Train loss: 0 Train Accuracy: 0.8810833333333333 Test Accuracy: 0.2825\n",
            "Epoch: 18 Train loss: 0 Train Accuracy: 0.8741666666666666 Test Accuracy: 0.2845\n",
            "Epoch: 19 Train loss: 0 Train Accuracy: 0.87875 Test Accuracy: 0.2395\n",
            "Epoch: 20 Train loss: 0 Train Accuracy: 0.909 Test Accuracy: 0.253\n",
            "Epoch: 21 Train loss: 0 Train Accuracy: 0.8886666666666667 Test Accuracy: 0.2585\n",
            "Epoch: 22 Train loss: 0 Train Accuracy: 0.86575 Test Accuracy: 0.239\n",
            "Epoch: 23 Train loss: 0 Train Accuracy: 0.91175 Test Accuracy: 0.2395\n",
            "Epoch: 24 Train loss: 0 Train Accuracy: 0.9198333333333333 Test Accuracy: 0.241\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}