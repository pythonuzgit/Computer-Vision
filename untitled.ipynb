{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": ".ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOeaE6SHKeq4Gh5yoIdrzgL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pythonuzgit/elmurodov/blob/master/untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHFf-rZNvR3j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUilcy1zvVac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "397af155-73ff-406f-ade4-5b1a34eeec08"
      },
      "source": [
        "!kaggle datasets download -d joeylimzy/flowers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading flowers.zip to /content\n",
            " 99% 275M/279M [00:02<00:00, 126MB/s]\n",
            "100% 279M/279M [00:02<00:00, 107MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjEfnqHdvTEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1294d3be-1d13-4663-d15b-78dd238ef4b7"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/flowers.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c0Uo7_sL1gf"
      },
      "source": [
        "Import all libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r89p4nxGL3cw"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import os\n",
        "from PIL import Image\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zpzr49INACh"
      },
      "source": [
        "Clean data and remove non images files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xMcQYO3L3tt"
      },
      "source": [
        "\n",
        "path = '/content/Flowers'\n",
        "\n",
        "\n",
        "for folder in os.listdir(path):\n",
        "  for img_file in os.listdir(os.path.join(path, folder)):\n",
        "    img_file = os.path.join(path, folder, img_file)\n",
        "\n",
        "\n",
        "    try:\n",
        "      img = Image.open(img_file)\n",
        "      if img.mode != 'RGB':\n",
        "        os.remove(img_file)\n",
        "\n",
        "    except:\n",
        "      os.remove(img_file)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnE7O52tOSbR"
      },
      "source": [
        "Data Preprocessing and convert to tensor format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7Tu7thtL3xC"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "                                transforms.Resize(255),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder('/content/Flowers', transform = transform)\n",
        "\n",
        "dataset_len = len(dataset)\n",
        "\n",
        "train_len, test_len = dataset_len - 1500, 1500\n",
        "\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [train_len, test_len])\n",
        "\n",
        "batch_size = 200\n",
        "\n",
        "#DataLoader\n",
        "\n",
        "train_set = DataLoader(dataset = train_set, shuffle = True, batch_size = batch_size)\n",
        "test_set = DataLoader(dataset = test_set, shuffle = True, batch_size = batch_size)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Dojzj9IQoYQ"
      },
      "source": [
        "If cuda available the use device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQd8DyBWL30P"
      },
      "source": [
        "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhD9jZWrL33X",
        "outputId": "354f8467-441f-4731-873c-fe5aee156754"
      },
      "source": [
        "print(dev)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8uvTPXlRX9F"
      },
      "source": [
        "Build CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6MRt-eBL36s",
        "outputId": "fb1e0dcd-5f9b-43f3-887b-35c62b5c7cf5"
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.dropout = nn.Dropout(p = 0.2)\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 6, kernel_size = 4)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 4)\n",
        "    self.conv3 = nn.Conv2d(in_channels = 12, out_channels = 14, kernel_size = 4)\n",
        "    self.conv4 = nn.Conv2d(in_channels = 14, out_channels = 16, kernel_size = 4)\n",
        "    self.conv5 = nn.Conv2d(in_channels = 16, out_channels = 20, kernel_size = 4)\n",
        "\n",
        "    \n",
        "    self.fc1 = nn.Linear(in_features = 20 * 4 * 4, out_features = 250)\n",
        "    self.fc2 = nn.Linear(in_features = 250, out_features = 200)\n",
        "    self.fc3 = nn.Linear(in_features = 200, out_features = 50)\n",
        "    self.fc4 = nn.Linear(in_features = 50, out_features = 10)\n",
        "    self.fc5 = nn.Linear(in_features = 10, out_features = 5)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.pool(F.relu(self.conv3(x)))\n",
        "    x = self.pool(F.relu(self.conv4(x)))\n",
        "    x = self.pool(F.relu(self.conv5(x)))\n",
        "\n",
        "\n",
        "\n",
        "    x = x.reshape(-1, 20 * 4 * 4)\n",
        "    x = self.dropout(F.relu(self.fc1(x)))\n",
        "    x = self.dropout(F.relu(self.fc2(x)))\n",
        "    x = self.dropout(F.relu(self.fc3(x)))\n",
        "    x = self.dropout(F.relu(self.fc4(x)))\n",
        "    x = self.fc5(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "net = Model().to(dev)\n",
        "\n",
        "print(net)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(4, 4), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 12, kernel_size=(4, 4), stride=(1, 1))\n",
            "  (conv3): Conv2d(12, 14, kernel_size=(4, 4), stride=(1, 1))\n",
            "  (conv4): Conv2d(14, 16, kernel_size=(4, 4), stride=(1, 1))\n",
            "  (conv5): Conv2d(16, 20, kernel_size=(4, 4), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=320, out_features=250, bias=True)\n",
            "  (fc2): Linear(in_features=250, out_features=200, bias=True)\n",
            "  (fc3): Linear(in_features=200, out_features=50, bias=True)\n",
            "  (fc4): Linear(in_features=50, out_features=10, bias=True)\n",
            "  (fc5): Linear(in_features=10, out_features=5, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fzyGtA_RcNd"
      },
      "source": [
        "Define Loss and Optimizer functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VucKTP_yRipr"
      },
      "source": [
        "creterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.001, weight_decay = 1e-5)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmkFjXD3So-h"
      },
      "source": [
        "Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dBM1VyKSm3w",
        "outputId": "7ae1a50e-f0d0-4331-8a0a-3f24f0615109"
      },
      "source": [
        "net.train()\n",
        "\n",
        "for epoch in range(25):\n",
        "  total_correct = 0.0\n",
        "  running_loss = 0.0\n",
        "  for i, (inputs, labels) in enumerate(train_set):\n",
        "    inputs, labels = inputs.to(dev), labels.to(dev)\n",
        "    output = net(inputs)\n",
        "    output_idx = torch.argmax(output, dim = 1)\n",
        "    total_correct += (labels == output_idx).sum().item()\n",
        "    optimizer.zero_grad()\n",
        "    loss = creterion(output, labels)\n",
        "    running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "  print(f'Epoch: {epoch}  Loss: {running_loss/train_len}  Accuracy: {(total_correct/train_len) * 100}%') \n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0  Loss: 1.61003753986025  Accuracy: 22.419825072886297%\n",
            "Epoch: 1  Loss: 1.573485589235934  Accuracy: 26.18075801749271%\n",
            "Epoch: 2  Loss: 1.5421663825087923  Accuracy: 27.900874635568513%\n",
            "Epoch: 3  Loss: 1.502217973634036  Accuracy: 30.466472303207%\n",
            "Epoch: 4  Loss: 1.4432846234769237  Accuracy: 32.798833819241985%\n",
            "Epoch: 5  Loss: 1.3781102047717257  Accuracy: 36.23906705539358%\n",
            "Epoch: 6  Loss: 1.3230082849719433  Accuracy: 40.49562682215743%\n",
            "Epoch: 7  Loss: 1.2762878399896205  Accuracy: 45.59766763848396%\n",
            "Epoch: 8  Loss: 1.2631140565038075  Accuracy: 48.075801749271136%\n",
            "Epoch: 9  Loss: 1.2307010020180973  Accuracy: 49.94169096209913%\n",
            "Epoch: 10  Loss: 1.188316718482415  Accuracy: 51.42857142857142%\n",
            "Epoch: 11  Loss: 1.153760187653689  Accuracy: 52.82798833819242%\n",
            "Epoch: 12  Loss: 1.111010439889424  Accuracy: 54.78134110787172%\n",
            "Epoch: 13  Loss: 1.0921918186779969  Accuracy: 54.3731778425656%\n",
            "Epoch: 14  Loss: 1.0521167304703516  Accuracy: 54.95626822157435%\n",
            "Epoch: 15  Loss: 1.0377555722397895  Accuracy: 57.434402332361515%\n",
            "Epoch: 16  Loss: 1.0169657937986858  Accuracy: 58.48396501457726%\n",
            "Epoch: 17  Loss: 1.032117483045895  Accuracy: 58.83381924198251%\n",
            "Epoch: 18  Loss: 0.9926636531818712  Accuracy: 58.5131195335277%\n",
            "Epoch: 19  Loss: 0.9967109303780269  Accuracy: 59.30029154518951%\n",
            "Epoch: 20  Loss: 1.0065419375027582  Accuracy: 60.7871720116618%\n",
            "Epoch: 21  Loss: 0.9816598297903211  Accuracy: 61.457725947521865%\n",
            "Epoch: 22  Loss: 0.9386392585042614  Accuracy: 63.06122448979592%\n",
            "Epoch: 23  Loss: 0.9394599487760672  Accuracy: 62.973760932944614%\n",
            "Epoch: 24  Loss: 0.9377863016142441  Accuracy: 61.19533527696793%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HihdbyvaeDrd"
      },
      "source": [
        "Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjTUCPpJeC2k",
        "outputId": "5db7d9ed-5e9f-4ca5-9b65-2facad9b62ab"
      },
      "source": [
        "with torch.no_grad():\n",
        "  net.eval()\n",
        "  total_loss = 0.0\n",
        "  total_correct = 0.0\n",
        "  for inputs, labels in test_set:\n",
        "    labels = labels.to(dev)\n",
        "    outputs = net(inputs.to(dev))\n",
        "    loss = creterion(outputs, labels)\n",
        "    total_loss += loss.item() * inputs.size(0)\n",
        "    output_idx = torch.argmax(outputs, dim = 1)\n",
        "    total_correct += sum(labels == output_idx)\n",
        "\n",
        "  print(f'Accuracy: {(total_correct / test_len) * 100}%  Loss: {total_loss / test_len}')  "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 63.266666412353516%  Loss: 0.9539333383242289\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}