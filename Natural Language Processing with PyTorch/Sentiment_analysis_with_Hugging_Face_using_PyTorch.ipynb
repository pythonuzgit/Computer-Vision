{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment analysis with Hugging Face using PyTorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMdi6th2WOfvrvKpARSlplP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pythonuzgit/elmurodov/blob/master/Natural%20Language%20Processing%20with%20PyTorch/Sentiment_analysis_with_Hugging_Face_using_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSAZ_ShTsgT1"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rsCtEzHYvhon",
        "outputId": "45663426-d81e-4a6f-8ae9-bb5474066a29"
      },
      "source": [
        "data = pd.read_csv('/content/apple-twitter-sentiment-texts.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow. Yall needa step it up @Apple RT @heynyla:...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What Happened To Apple Inc?   http://t.co/FJEX...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Thank u @apple I can now compile all of the pi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The oddly uplifting story of the Apple co-foun...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@apple can i exchange my iphone for a differen...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment\n",
              "0  Wow. Yall needa step it up @Apple RT @heynyla:...         -1\n",
              "1  What Happened To Apple Inc?   http://t.co/FJEX...          0\n",
              "2  Thank u @apple I can now compile all of the pi...          1\n",
              "3  The oddly uplifting story of the Apple co-foun...          0\n",
              "4  @apple can i exchange my iphone for a differen...          0"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ8jLOgIvhiG",
        "outputId": "7a760c8e-5be2-4f89-c4ca-aec2dd860edc"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1630, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK57UC17c54V"
      },
      "source": [
        "Let's label encode the sentiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8Z4MElZc8RA"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "lb= LabelEncoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VQHzLmxc8MW",
        "outputId": "410c2306-af1b-4c13-cdda-27965f004c0d"
      },
      "source": [
        "lb.fit(data['sentiment'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jIPq3fcc7_N",
        "outputId": "0110ddd9-23af-4813-92d8-0b624833664e"
      },
      "source": [
        "classes= list(lb.classes_)\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-1, 0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3J-XiajcnEJ"
      },
      "source": [
        "data['sentiment']= lb.fit_transform(data['sentiment'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "47SRy0bKdfHF",
        "outputId": "c802aabc-4aaf-4992-a990-8d45942cff60"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow. Yall needa step it up @Apple RT @heynyla:...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What Happened To Apple Inc?   http://t.co/FJEX...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Thank u @apple I can now compile all of the pi...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The oddly uplifting story of the Apple co-foun...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@apple can i exchange my iphone for a differen...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment\n",
              "0  Wow. Yall needa step it up @Apple RT @heynyla:...          0\n",
              "1  What Happened To Apple Inc?   http://t.co/FJEX...          1\n",
              "2  Thank u @apple I can now compile all of the pi...          2\n",
              "3  The oddly uplifting story of the Apple co-foun...          1\n",
              "4  @apple can i exchange my iphone for a differen...          1"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKMB69o_de4O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "l4SYf6mUv9w2",
        "outputId": "8f77ae2a-9c8c-4dd9-ffa2-6964203ecc45"
      },
      "source": [
        "sns.countplot(data['sentiment'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f24c313f9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBQ2FKWlxXn0",
        "outputId": "529f49e3-1b2b-4233-edbe-f1766cde83b9"
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text         0\n",
              "sentiment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S50AOEBFwGt0"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK_9ZO9dwFjO"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwskgxtCwSQI"
      },
      "source": [
        "A function to clean data it removes all the punctuation marks, urls etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIcIGwqLwFgD"
      },
      "source": [
        "def clean_text(text):\n",
        "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
        "    and remove words containing numbers.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KmZgNKjwFcv"
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x: clean_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITX1s3ihwqLR"
      },
      "source": [
        "Checking the maximum length of tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZPtSZDvwFVX",
        "outputId": "dab97d45-fb0f-4e78-f169-c3b1d267c5b9"
      },
      "source": [
        "data['text'].apply(lambda x:len(str(x).split())).max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XepXiYZlwuFE",
        "outputId": "330f28a5-6b20-4aea-bdd1-affc00de1498"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wow yall needa step it up apple rt heynyla mus...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what happened to apple inc     aapl apple mone...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thank u apple i can now compile all of the pic...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the oddly uplifting story of the apple cofound...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>apple can i exchange my iphone for a different...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment\n",
              "0  wow yall needa step it up apple rt heynyla mus...          0\n",
              "1  what happened to apple inc     aapl apple mone...          1\n",
              "2  thank u apple i can now compile all of the pic...          2\n",
              "3  the oddly uplifting story of the apple cofound...          1\n",
              "4  apple can i exchange my iphone for a different...          1"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcJEqLZIxFdN"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L3pIhbQoMv2"
      },
      "source": [
        "Importing transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcpRBMU_xFZn"
      },
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdJiDxQpxFVf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtK427bYwzoW",
        "outputId": "1246f670-611b-4a58-b194-95d986122656"
      },
      "source": [
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f2532c89790>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAM_tZKVoUVk"
      },
      "source": [
        "Setting device to GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvH-GDVHw93T",
        "outputId": "37f1d4f6-0b93-4770-f4ff-04db15a4ab77"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6c1b7yFw90Z"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxgFmgHVw9xP"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLn5VUjRxdXX"
      },
      "source": [
        "Choosing Sequence Length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaVhR6_xw9te"
      },
      "source": [
        "token_lens = []\n",
        "for txt in data.text:\n",
        "    \n",
        "    tokens = tokenizer.encode(txt, max_length=512, truncation = True)\n",
        "    token_lens.append(len(tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "sxMonxmSxpDz",
        "outputId": "289d26b1-bf68-403b-d34e-f1ce616eb28c"
      },
      "source": [
        "sns.distplot(token_lens)\n",
        "plt.xlim([0, 256]);\n",
        "plt.xlabel('Token count')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Token count')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COORIn2WxvNh"
      },
      "source": [
        "MAX_LEN = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw6ltpsWyINM"
      },
      "source": [
        "Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtapjrAYveQh"
      },
      "source": [
        "class appletweet(Dataset):\n",
        "  def __init__(self, text, targets, tokenizer, max_len):\n",
        "    self.text = text\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.text)\n",
        "\n",
        "\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    text = str(self.text[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "        text, \n",
        "        add_special_tokens = True,\n",
        "        max_length = self.max_len,\n",
        "        return_token_type_ids = False,\n",
        "        pad_to_max_length = True,\n",
        "        #padding = True,\n",
        "        return_attention_mask = True,\n",
        "        return_tensors = 'pt',\n",
        "        truncation = True\n",
        "\n",
        "    ) \n",
        "    return {\n",
        "        'reviews_text' : text,\n",
        "        'input_ids' : encoding['input_ids'].flatten(),\n",
        "        'attention_mask' : encoding['attention_mask'].flatten(),\n",
        "        'targets' : torch.tensor(target, dtype = torch.long)\n",
        "    }   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdw9u0rLqdxH"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGYXdoaqrAFt",
        "outputId": "204b8ff8-d90b-4076-9994-d1143c69fc3a"
      },
      "source": [
        "train, val = train_test_split(\n",
        "  data,\n",
        "  test_size=0.1,\n",
        "  random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "train.shape,val.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1467, 2), (163, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY_IbBhretV"
      },
      "source": [
        "Dataloader:- converts data to be fed into classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQGmzzR6t62Q"
      },
      "source": [
        "def create_data_loader(data, tokenizer, max_len, batch_size):\n",
        "\n",
        "  ds = appletweet(\n",
        "      text = data.text.to_numpy(),\n",
        "      targets = data.sentiment.to_numpy(),\n",
        "      tokenizer = tokenizer,\n",
        "      max_len = max_len\n",
        "  )\n",
        "  return DataLoader(\n",
        "      ds, \n",
        "      batch_size = batch_size,\n",
        "      num_workers = 2\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_data_loader = create_data_loader(train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "#test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXhFTIEqotN2",
        "outputId": "568098bc-d8c0-46a7-ea58-e8b716d25c6f"
      },
      "source": [
        "df = next(iter(train_data_loader))\n",
        "df.keys()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['reviews_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv5ed6nDCmGp",
        "outputId": "c5aeb817-2c95-46cf-c1a7-89706314f2f0"
      },
      "source": [
        "print(df['attention_mask'].shape)\n",
        "print(df['input_ids'].shape)\n",
        "print(df['targets'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 50])\n",
            "torch.Size([32, 50])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk1jawNIDLE2"
      },
      "source": [
        "Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LId8VEJDKTp",
        "outputId": "4f2420f7-134d-44cf-f76a-2ffea91a4bd7"
      },
      "source": [
        "\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-cased\", return_dict=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFnOOJ5GClrX",
        "outputId": "9d1dbda3-ec59-42c4-c52e-c215226edeae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "\n",
        "    self.drop = nn.Dropout(p = 0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "\n",
        "    _,pooled_output = self.bert(input_ids = input_ids,\n",
        "                                attention_mask = attention_mask, return_dict=False)\n",
        "\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9c6e8f741dfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSentimentClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSentimentClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPRE_TRAINED_MODEL_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTh8J-GfCln5"
      },
      "source": [
        "n_classes = 3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLP2B26mFnBQ",
        "outputId": "d62e70d7-34fc-414c-a1e2-587df81d61b2"
      },
      "source": [
        "model = SentimentClassifier(n_classes)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYikDZW8FvV3"
      },
      "source": [
        "input_ids = df['input_ids'].to(device)\n",
        "attention_mask = df['attention_mask'].to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnw1JkiUMznQ",
        "outputId": "04cacee6-324e-4fed-8aa0-a139cf8c550f"
      },
      "source": [
        "print(input_ids.shape)\n",
        "print(attention_mask.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 50])\n",
            "torch.Size([32, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyOIApQmNFP3"
      },
      "source": [
        "Softmax function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Bgt2KWnNAm8"
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UypUoZCZNWCj",
        "outputId": "4660ca96-7adf-40ab-9810-5ff9e6fbca4b"
      },
      "source": [
        "F.softmax(model(input_ids, attention_mask), dim=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2943, 0.4885, 0.2171],\n",
              "        [0.2366, 0.5886, 0.1748],\n",
              "        [0.4625, 0.3649, 0.1727],\n",
              "        [0.3433, 0.4497, 0.2070],\n",
              "        [0.3922, 0.3610, 0.2468],\n",
              "        [0.2540, 0.5362, 0.2098],\n",
              "        [0.2847, 0.4342, 0.2811],\n",
              "        [0.3939, 0.4255, 0.1805],\n",
              "        [0.2217, 0.5599, 0.2185],\n",
              "        [0.4234, 0.4298, 0.1468],\n",
              "        [0.3718, 0.3927, 0.2354],\n",
              "        [0.3353, 0.4063, 0.2584],\n",
              "        [0.3159, 0.3928, 0.2912],\n",
              "        [0.1993, 0.3641, 0.4366],\n",
              "        [0.3159, 0.5319, 0.1522],\n",
              "        [0.3333, 0.4530, 0.2137],\n",
              "        [0.3775, 0.4626, 0.1600],\n",
              "        [0.4107, 0.4549, 0.1344],\n",
              "        [0.4119, 0.3783, 0.2098],\n",
              "        [0.3324, 0.3624, 0.3053],\n",
              "        [0.3394, 0.4366, 0.2240],\n",
              "        [0.3005, 0.4544, 0.2451],\n",
              "        [0.3600, 0.4312, 0.2087],\n",
              "        [0.4356, 0.3313, 0.2331],\n",
              "        [0.3827, 0.4012, 0.2161],\n",
              "        [0.2922, 0.4746, 0.2332],\n",
              "        [0.3139, 0.4529, 0.2332],\n",
              "        [0.3360, 0.4839, 0.1801],\n",
              "        [0.4615, 0.3760, 0.1625],\n",
              "        [0.3106, 0.5075, 0.1819],\n",
              "        [0.2780, 0.5220, 0.2001],\n",
              "        [0.3859, 0.4619, 0.1522]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6EpSGykV7jP",
        "outputId": "87a13223-5f44-4b1a-b5bc-47a5e030dfad"
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of SentimentClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (drop): Dropout(p=0.3, inplace=False)\n",
              "  (out): Linear(in_features=768, out_features=3, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np22jR9lWUnL"
      },
      "source": [
        "Use loss function as Cross Entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fzC0NhYWGLg"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr = 2e-5, correct_bias = False)\n",
        "\n",
        "total_steps = len(train_data_loader)*EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                   num_warmup_steps = total_steps, num_training_steps=total_steps)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IieItUfZXyKX"
      },
      "source": [
        "Training with epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DTxyDV-XGSU"
      },
      "source": [
        "def train_epoch(model,data_loader,loss_fn,optimizer,device,scheduler, n_examples):  \n",
        "\n",
        "  model = model.train()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d['input_ids'].to(device)\n",
        "    attention_mask = d['attention_mask'].to(device)\n",
        "    targets = d['targets'].to(device)\n",
        "    outputs = model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "\n",
        "    _,preds = torch.max(outputs, dim = 1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGof2k1lZ43o"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krshs6RvZ0q9"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d['input_ids'].to(device)\n",
        "      attention_mask = d['attention_mask'].to(device)\n",
        "      targets = d['targets'].to(device)\n",
        "      outputs = model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "\n",
        "      _,preds = torch.max(outputs, dim = 1)\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions +=  torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdavlRozb4Ni"
      },
      "source": [
        "Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_0-uDTGbzPt"
      },
      "source": [
        "from collections import defaultdict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LacJdDrdb9Js",
        "outputId": "df1d5d96-5b2e-4e9f-8bc0-e9f3c56d5045"
      },
      "source": [
        "%%time\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(model,train_data_loader,loss_fn,optimizer,device,scheduler,len(train))\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(model,val_data_loader,loss_fn,device,len(val))\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n",
            "Train loss 0.9567856918210569 accuracy 0.5316973415132924\n",
            "Val   loss 0.7508474787076315 accuracy 0.7730061349693251\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n",
            "Train loss 0.6671257958464001 accuracy 0.7695978186775733\n",
            "Val   loss 0.4965347995360692 accuracy 0.8159509202453987\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n",
            "Train loss 0.4214904865492945 accuracy 0.8548057259713702\n",
            "Val   loss 0.47677338620026904 accuracy 0.852760736196319\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n",
            "Train loss 0.2576787374589754 accuracy 0.929107021131561\n",
            "Val   loss 0.44687817990779877 accuracy 0.8343558282208589\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n",
            "Train loss 0.14082108830790158 accuracy 0.9652351738241309\n",
            "Val   loss 0.491527500251929 accuracy 0.8404907975460123\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n",
            "Train loss 0.08466870309380085 accuracy 0.978186775732788\n",
            "Val   loss 0.41995356666545075 accuracy 0.8773006134969326\n",
            "\n",
            "Epoch 7/10\n",
            "----------\n",
            "Train loss 0.04996943743595773 accuracy 0.9843217450579413\n",
            "Val   loss 0.4479474077622096 accuracy 0.8957055214723927\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n",
            "Train loss 0.07059536299809975 accuracy 0.9822767552828903\n",
            "Val   loss 0.5926942778751254 accuracy 0.8588957055214724\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n",
            "Train loss 0.021686238067163882 accuracy 0.9925017041581459\n",
            "Val   loss 0.5618368809421858 accuracy 0.8711656441717791\n",
            "\n",
            "Epoch 10/10\n",
            "----------\n",
            "Train loss 0.02958426948221724 accuracy 0.9918200408997955\n",
            "Val   loss 0.7266563673814138 accuracy 0.8711656441717791\n",
            "\n",
            "CPU times: user 1h 47min 53s, sys: 8min 57s, total: 1h 56min 50s\n",
            "Wall time: 1h 56min 35s\n"
          ]
        }
      ]
    }
  ]
}