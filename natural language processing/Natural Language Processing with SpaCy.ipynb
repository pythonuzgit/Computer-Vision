{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>class</th>\n",
       "      <th>response_text</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>response_1</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>I try and avoid this sort of conflict</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>response_2</td>\n",
       "      <td>flagged</td>\n",
       "      <td>Had a friend open up to me about his mental ad...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>response_3</td>\n",
       "      <td>flagged</td>\n",
       "      <td>I saved a girl from suicide once. She was goin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>response_4</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>i cant think of one really...i think i may hav...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>response_5</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>Only really one friend who doesn't fit into th...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  response_id        class                                      response_text  \\\n",
       "0  response_1  not_flagged              I try and avoid this sort of conflict   \n",
       "1  response_2      flagged  Had a friend open up to me about his mental ad...   \n",
       "2  response_3      flagged  I saved a girl from suicide once. She was goin...   \n",
       "3  response_4  not_flagged  i cant think of one really...i think i may hav...   \n",
       "4  response_5  not_flagged  Only really one friend who doesn't fit into th...   \n",
       "\n",
       "  Unnamed: 3  Unnamed: 4 Unnamed: 5  Unnamed: 6 Unnamed: 7  \n",
       "0        NaN         NaN        NaN         NaN        NaN  \n",
       "1        NaN         NaN        NaN         NaN        NaN  \n",
       "2        NaN         NaN        NaN         NaN        NaN  \n",
       "3        NaN         NaN        NaN         NaN        NaN  \n",
       "4                    NaN        NaN         NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('datasets_897_1638_Sheet_1.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>response_text</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>I try and avoid this sort of conflict</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flagged</td>\n",
       "      <td>Had a friend open up to me about his mental ad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flagged</td>\n",
       "      <td>I saved a girl from suicide once. She was goin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>i cant think of one really...i think i may hav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>Only really one friend who doesn't fit into th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class                                      response_text  category_id\n",
       "0  not_flagged              I try and avoid this sort of conflict            0\n",
       "1      flagged  Had a friend open up to me about his mental ad...            1\n",
       "2      flagged  I saved a girl from suicide once. She was goin...            1\n",
       "3  not_flagged  i cant think of one really...i think i may hav...            0\n",
       "4  not_flagged  Only really one friend who doesn't fit into th...            0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "col = ['class', 'response_text']\n",
    "\n",
    "df_train = df_train[col]\n",
    "df_train = df_train[pd.notnull(df_train['response_text'])]\n",
    "\n",
    "df_train.columns = ['class', 'response_text']\n",
    "\n",
    "df_train['category_id'] = df_train['class'].factorize()[0]\n",
    "\n",
    "category_id_df_train = df_train[['class', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "\n",
    "category_to_id = dict(category_id_df_train.values)\n",
    "\n",
    "id_to_category = dict(category_id_df_train[['category_id', 'class']].values)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80 entries, 0 to 79\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   class          80 non-null     object\n",
      " 1   response_text  80 non-null     object\n",
      " 2   category_id    80 non-null     int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokening the data with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import spacy\n",
    "spacy.load(\"en_core_web_sm\")\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of punctuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chi/anaconda3/envs/nltkEnv/lib/python3.7/site-packages/spacy/util.py:271: UserWarning: [W031] Model 'en_core_web_sm' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.0). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "punctuations = string.punctuation\n",
    "#create list of stopwords\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "#load English tokenizer, tagger, parser, NER and word vectors\n",
    "\n",
    "parser = English()\n",
    "\n",
    "#creating tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    #creating token object, which is used to create documents with linguistic anntations\n",
    "    mytokens = parser(sentence)\n",
    "    \n",
    "    #Lemmatizing each token\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens]\n",
    "    \n",
    "    \n",
    "    #Removing stopwords\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a custom transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "    \n",
    "    def fit(self, X, y = None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep = True):\n",
    "        return {}\n",
    "    \n",
    "    \n",
    "    \n",
    "#Basic function to clean the text\n",
    "def clean_text(text):\n",
    "    \n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization Feature Engeneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range = (1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df_train['response_text']\n",
    "ylabels = df_train['category_id']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a pipeline and generating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the pipeline components using fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chi/anaconda3/envs/nltkEnv/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cleaner', <__main__.predictors object at 0x7f83b3bc5750>),\n",
       "                ('vectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 t...\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function spacy_tokenizer at 0x7f83b338b710>,\n",
       "                                 vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "#Create pipeline using Bag of words\n",
    "\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                ('vectorizer', bow_vector),\n",
    "                ('classifier', classifier)])\n",
    "\n",
    "#model generation \n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how our model actually performs, using the metrics modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.75\n",
      "Logistic Regression Precision: 1.0\n",
      "Logistic Regression Recall: 0.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "#Model accuracy\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", metrics.accuracy_score(y_test, predicted))\n",
    "\n",
    "print(\"Logistic Regression Precision:\", metrics.precision_score(y_test, predicted))\n",
    "\n",
    "print(\"Logistic Regression Recall:\", metrics.recall_score(y_test, predicted))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
